{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "w1= tf.Variable(tf.random_normal([2, 3], stddev=1, seed=1))\n",
    "w2= tf.Variable(tf.random_normal([3, 1], stddev=1, seed=1))\n",
    "x = tf.placeholder(tf.float32, shape=(None, 2), name=\"x-input\")\n",
    "y_= tf.placeholder(tf.float32, shape=(None, 1), name='y-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.matmul(x, w1)\n",
    "y = tf.matmul(a, w2)\n",
    "y = tf.sigmoid(y)\n",
    "cross_entropy = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0))\n",
    "                                + (1 - y_) * tf.log(tf.clip_by_value(1 - y, 1e-10, 1.0)))\n",
    "train_step = tf.train.AdamOptimizer(0.05).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdm = RandomState(1)\n",
    "X = rdm.rand(128,2)\n",
    "Y = [[int(x1+x2 < 1)] for (x1, x2) in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.8113182   1.4845988   0.06532937]\n",
      " [-2.4427042   0.0992484   0.5912243 ]]\n",
      "[[-0.8113182 ]\n",
      " [ 1.4845988 ]\n",
      " [ 0.06532937]]\n",
      "\n",
      "\n",
      "After 0 training step(s), cross entropy on all data is 1.7449\n",
      "After 1000 training step(s), cross entropy on all data is 0.608216\n",
      "After 2000 training step(s), cross entropy on all data is 0.60817\n",
      "After 3000 training step(s), cross entropy on all data is 0.608196\n",
      "After 4000 training step(s), cross entropy on all data is 0.608173\n",
      "\n",
      "\n",
      "[[ 2.4582645e-05  1.2987966e-06  1.5226488e+00]\n",
      " [-5.1556799e-05 -2.7105016e-06  6.9537520e-02]]\n",
      "[[ 2.9138903e-07]\n",
      " [ 3.4816104e-08]\n",
      " [-1.0696169e+00]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    # 输出目前（未经训练）的参数取值。\n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w2))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # 训练模型。\n",
    "    STEPS = 5000\n",
    "    for i in range(STEPS):\n",
    "        start = (i*batch_size) % 128\n",
    "        end = (i*batch_size) % 128 + batch_size\n",
    "        sess.run([train_step, y, y_], feed_dict={x: X[start:end], y_: Y[start:end]})\n",
    "        if i % 1000 == 0:\n",
    "            total_cross_entropy = sess.run(cross_entropy, feed_dict={x: X, y_: Y})\n",
    "            print(\"After %d training step(s), cross entropy on all data is %g\" % (i, total_cross_entropy))\n",
    "    \n",
    "    # 输出训练后的参数取值。\n",
    "    print(\"\\n\")\n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
